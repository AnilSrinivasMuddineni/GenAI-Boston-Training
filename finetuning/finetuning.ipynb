{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "858bf51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# conda environments:\n",
      "#\n",
      "base                   C:\\ProgramData\\miniconda3\n",
      "BIG-GenAI-env        * C:\\Users\\hp\\.conda\\envs\\BIG-GenAI-env\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda env list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "949611ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (25.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~orch (c:\\Users\\hp\\.conda\\envs\\BIG-GenAI-env\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orch (c:\\Users\\hp\\.conda\\envs\\BIG-GenAI-env\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orch (c:\\Users\\hp\\.conda\\envs\\BIG-GenAI-env\\Lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~orch (c:\\Users\\hp\\.conda\\envs\\BIG-GenAI-env\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orch (c:\\Users\\hp\\.conda\\envs\\BIG-GenAI-env\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orch (c:\\Users\\hp\\.conda\\envs\\BIG-GenAI-env\\Lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~orch (c:\\Users\\hp\\.conda\\envs\\BIG-GenAI-env\\Lib\\site-packages)\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Building wheel for tokenizers (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [62 lines of output]\n",
      "      C:\\Users\\hp\\AppData\\Local\\Temp\\pip-build-env-r1w_0m_y\\overlay\\Lib\\site-packages\\setuptools\\dist.py:759: SetuptoolsDeprecationWarning: License classifiers are deprecated.\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              Please consider removing the following classifiers in favor of a SPDX license expression:\n",
      "      \n",
      "              License :: OSI Approved :: Apache Software License\n",
      "      \n",
      "              See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        self._finalize_license_expression()\n",
      "      running bdist_wheel\n",
      "      running build\n",
      "      running build_py\n",
      "      creating build\\lib.win-amd64-cpython-313\\tokenizers\n",
      "      copying py_src\\tokenizers\\__init__.py -> build\\lib.win-amd64-cpython-313\\tokenizers\n",
      "      creating build\\lib.win-amd64-cpython-313\\tokenizers\\models\n",
      "      copying py_src\\tokenizers\\models\\__init__.py -> build\\lib.win-amd64-cpython-313\\tokenizers\\models\n",
      "      creating build\\lib.win-amd64-cpython-313\\tokenizers\\decoders\n",
      "      copying py_src\\tokenizers\\decoders\\__init__.py -> build\\lib.win-amd64-cpython-313\\tokenizers\\decoders\n",
      "      creating build\\lib.win-amd64-cpython-313\\tokenizers\\normalizers\n",
      "      copying py_src\\tokenizers\\normalizers\\__init__.py -> build\\lib.win-amd64-cpython-313\\tokenizers\\normalizers\n",
      "      creating build\\lib.win-amd64-cpython-313\\tokenizers\\pre_tokenizers\n",
      "      copying py_src\\tokenizers\\pre_tokenizers\\__init__.py -> build\\lib.win-amd64-cpython-313\\tokenizers\\pre_tokenizers\n",
      "      creating build\\lib.win-amd64-cpython-313\\tokenizers\\processors\n",
      "      copying py_src\\tokenizers\\processors\\__init__.py -> build\\lib.win-amd64-cpython-313\\tokenizers\\processors\n",
      "      creating build\\lib.win-amd64-cpython-313\\tokenizers\\trainers\n",
      "      copying py_src\\tokenizers\\trainers\\__init__.py -> build\\lib.win-amd64-cpython-313\\tokenizers\\trainers\n",
      "      creating build\\lib.win-amd64-cpython-313\\tokenizers\\implementations\n",
      "      copying py_src\\tokenizers\\implementations\\base_tokenizer.py -> build\\lib.win-amd64-cpython-313\\tokenizers\\implementations\n",
      "      copying py_src\\tokenizers\\implementations\\bert_wordpiece.py -> build\\lib.win-amd64-cpython-313\\tokenizers\\implementations\n",
      "      copying py_src\\tokenizers\\implementations\\byte_level_bpe.py -> build\\lib.win-amd64-cpython-313\\tokenizers\\implementations\n",
      "      copying py_src\\tokenizers\\implementations\\char_level_bpe.py -> build\\lib.win-amd64-cpython-313\\tokenizers\\implementations\n",
      "      copying py_src\\tokenizers\\implementations\\sentencepiece_bpe.py -> build\\lib.win-amd64-cpython-313\\tokenizers\\implementations\n",
      "      copying py_src\\tokenizers\\implementations\\sentencepiece_unigram.py -> build\\lib.win-amd64-cpython-313\\tokenizers\\implementations\n",
      "      copying py_src\\tokenizers\\implementations\\__init__.py -> build\\lib.win-amd64-cpython-313\\tokenizers\\implementations\n",
      "      creating build\\lib.win-amd64-cpython-313\\tokenizers\\tools\n",
      "      copying py_src\\tokenizers\\tools\\visualizer.py -> build\\lib.win-amd64-cpython-313\\tokenizers\\tools\n",
      "      copying py_src\\tokenizers\\tools\\__init__.py -> build\\lib.win-amd64-cpython-313\\tokenizers\\tools\n",
      "      copying py_src\\tokenizers\\__init__.pyi -> build\\lib.win-amd64-cpython-313\\tokenizers\n",
      "      copying py_src\\tokenizers\\models\\__init__.pyi -> build\\lib.win-amd64-cpython-313\\tokenizers\\models\n",
      "      copying py_src\\tokenizers\\decoders\\__init__.pyi -> build\\lib.win-amd64-cpython-313\\tokenizers\\decoders\n",
      "      copying py_src\\tokenizers\\normalizers\\__init__.pyi -> build\\lib.win-amd64-cpython-313\\tokenizers\\normalizers\n",
      "      copying py_src\\tokenizers\\pre_tokenizers\\__init__.pyi -> build\\lib.win-amd64-cpython-313\\tokenizers\\pre_tokenizers\n",
      "      copying py_src\\tokenizers\\processors\\__init__.pyi -> build\\lib.win-amd64-cpython-313\\tokenizers\\processors\n",
      "      copying py_src\\tokenizers\\trainers\\__init__.pyi -> build\\lib.win-amd64-cpython-313\\tokenizers\\trainers\n",
      "      copying py_src\\tokenizers\\tools\\visualizer-styles.css -> build\\lib.win-amd64-cpython-313\\tokenizers\\tools\n",
      "      running build_ext\n",
      "      running build_rust\n",
      "      error: can't find Rust compiler\n",
      "      \n",
      "      If you are using an outdated pip version, it is possible a prebuilt wheel is available for this package but pip is not able to install from it. Installing from the wheel would avoid the need for a Rust compiler.\n",
      "      \n",
      "      To update pip, run:\n",
      "      \n",
      "          pip install --upgrade pip\n",
      "      \n",
      "      and then retry package installation.\n",
      "      \n",
      "      If you did intend to build this package from source, try installing a Rust compiler from your system package manager and ensure it is on the PATH during installation. Alternatively, rustup (available at https://rustup.rs) is the recommended way to download and update the Rust compiler toolchain.\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for tokenizers\n",
      "ERROR: Failed to build installable wheels for some pyproject.toml based projects (tokenizers)\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip\n",
    "%pip install --disable-pip-version-check \\\n",
    "    torch==2.6.0 \\\n",
    "    torchdata==0.11.0 --quiet\n",
    "\n",
    "%pip install \\\n",
    "    transformers==4.27.2 \\\n",
    "    datasets==2.11.0 \\\n",
    "    evaluate==0.4.0 \\\n",
    "    rouge_score==0.1.2 \\\n",
    "    loralib==0.1.1 \\\n",
    "    peft==0.3.0 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad853da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Now you can access the environment variables\n",
    "api_key = os.getenv(\"HF_TOKEN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eba8d18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (3.6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from datasets) (2.2.6)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from datasets) (0.32.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~orch (c:\\Users\\hp\\.conda\\envs\\BIG-GenAI-env\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orch (c:\\Users\\hp\\.conda\\envs\\BIG-GenAI-env\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orch (c:\\Users\\hp\\.conda\\envs\\BIG-GenAI-env\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78631999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.52.4-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from transformers) (0.32.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from requests->transformers) (2025.4.26)\n",
      "Downloading transformers-4.52.4-py3-none-any.whl (10.5 MB)\n",
      "   ---------------------------------------- 0.0/10.5 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 3.7/10.5 MB 19.5 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 3.7/10.5 MB 19.5 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 5.2/10.5 MB 8.1 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 6.3/10.5 MB 7.5 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 6.8/10.5 MB 6.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 7.9/10.5 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.9/10.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.2/10.5 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.5/10.5 MB 6.0 MB/s eta 0:00:00\n",
      "Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
      "Installing collected packages: safetensors, transformers\n",
      "\n",
      "   ---------------------------------------- 0/2 [safetensors]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   ---------------------------------------- 2/2 [transformers]\n",
      "\n",
      "Successfully installed safetensors-0.5.3 transformers-4.52.4\n"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a7322e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-2.7.0-cp313-cp313-win_amd64.whl.metadata (29 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from torch) (1.14.0)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from torch) (78.1.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Using cached MarkupSafe-3.0.2-cp313-cp313-win_amd64.whl.metadata (4.1 kB)\n",
      "Using cached torch-2.7.0-cp313-cp313-win_amd64.whl (212.5 MB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp313-cp313-win_amd64.whl (15 kB)\n",
      "Using cached networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "Installing collected packages: networkx, MarkupSafe, jinja2, torch\n",
      "\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------------------------------------- 0/4 [networkx]\n",
      "   ---------- ----------------------------- 1/4 [MarkupSafe]\n",
      "   -------------------- ------------------- 2/4 [jinja2]\n",
      "   -------------------- ------------------- 2/4 [jinja2]\n",
      "   -------------------- ------------------- 2/4 [jinja2]\n",
      "   -------------------- ------------------- 2/4 [jinja2]\n",
      "   -------------------- ------------------- 2/4 [jinja2]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ---------------------------------------- 4/4 [torch]\n",
      "\n",
      "Successfully installed MarkupSafe-3.0.2 jinja2-3.1.6 networkx-3.5 torch-2.7.0\n"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f76ffe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: datasets>=2.0.0 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from evaluate) (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from evaluate) (2.2.6)\n",
      "Requirement already satisfied: dill in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from evaluate) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from evaluate) (0.32.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from evaluate) (24.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from datasets>=2.0.0->evaluate) (20.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.0)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (3.10)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from huggingface-hub>=0.7.0->evaluate) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from requests>=2.19.0->evaluate) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from requests>=2.19.0->evaluate) (2025.4.26)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from tqdm>=4.62.1->evaluate) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
      "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "Installing collected packages: evaluate\n",
      "Successfully installed evaluate-0.4.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~orch (c:\\Users\\hp\\.conda\\envs\\BIG-GenAI-env\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orch (c:\\Users\\hp\\.conda\\envs\\BIG-GenAI-env\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orch (c:\\Users\\hp\\.conda\\envs\\BIG-GenAI-env\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "! pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caa1192c-deb5-48b9-8eb6-aaa61811f0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig, TrainingArguments, Trainer\n",
    "import torch\n",
    "import time\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f73f223",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\.conda\\envs\\BIG-GenAI-env\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\hp\\.cache\\huggingface\\hub\\datasets--knkarthick--dialogsum. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Generating train split:   0%|          | 0/12460 [00:00<?, ? examples/s]c:\\Users\\hp\\.conda\\envs\\BIG-GenAI-env\\Lib\\site-packages\\datasets\\utils\\file_utils.py:1213: FutureWarning: The 'verbose' keyword in pd.read_csv is deprecated and will be removed in a future version.\n",
      "  return pd.read_csv(xopen(filepath_or_buffer, \"rb\", download_config=download_config), **kwargs)\n",
      "Generating train split:  80%|████████  | 10000/12460 [00:00<00:00, 40975.21 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization took: 41.05 ms\n",
      "Type conversion took: 83.74 ms\n",
      "Parser memory cleanup took: 0.02 ms\n",
      "Tokenization took: 16.66 ms\n",
      "Type conversion took: 21.57 ms\n",
      "Parser memory cleanup took: 0.01 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 12460/12460 [00:00<00:00, 40695.71 examples/s]\n",
      "Generating validation split:   0%|          | 0/500 [00:00<?, ? examples/s]c:\\Users\\hp\\.conda\\envs\\BIG-GenAI-env\\Lib\\site-packages\\datasets\\utils\\file_utils.py:1213: FutureWarning: The 'verbose' keyword in pd.read_csv is deprecated and will be removed in a future version.\n",
      "  return pd.read_csv(xopen(filepath_or_buffer, \"rb\", download_config=download_config), **kwargs)\n",
      "Generating validation split: 100%|██████████| 500/500 [00:00<00:00, 18471.58 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization took: 1.98 ms\n",
      "Type conversion took: 5.19 ms\n",
      "Parser memory cleanup took: 0.01 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating test split:   0%|          | 0/1500 [00:00<?, ? examples/s]c:\\Users\\hp\\.conda\\envs\\BIG-GenAI-env\\Lib\\site-packages\\datasets\\utils\\file_utils.py:1213: FutureWarning: The 'verbose' keyword in pd.read_csv is deprecated and will be removed in a future version.\n",
      "  return pd.read_csv(xopen(filepath_or_buffer, \"rb\", download_config=download_config), **kwargs)\n",
      "Generating test split: 100%|██████████| 1500/1500 [00:00<00:00, 36218.16 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization took: 7.30 ms\n",
      "Type conversion took: 11.75 ms\n",
      "Parser memory cleanup took: 0.01 ms\n"
     ]
    }
   ],
   "source": [
    "huggingface_dataset_name = \"knkarthick/dialogsum\"\n",
    "\n",
    "dataset = load_dataset(\"knkarthick/dialogsum\", verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "009c54ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 12460\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 500\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 1500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c4c7e66-ddd9-43a1-b508-5aef76c21a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'train_0',\n",
       " 'dialogue': \"#Person1#: Hi, Mr. Smith. I'm Doctor Hawkins. Why are you here today?\\n#Person2#: I found it would be a good idea to get a check-up.\\n#Person1#: Yes, well, you haven't had one for 5 years. You should have one every year.\\n#Person2#: I know. I figure as long as there is nothing wrong, why go see the doctor?\\n#Person1#: Well, the best way to avoid serious illnesses is to find out about them early. So try to come at least once a year for your own good.\\n#Person2#: Ok.\\n#Person1#: Let me see here. Your eyes and ears look fine. Take a deep breath, please. Do you smoke, Mr. Smith?\\n#Person2#: Yes.\\n#Person1#: Smoking is the leading cause of lung cancer and heart disease, you know. You really should quit.\\n#Person2#: I've tried hundreds of times, but I just can't seem to kick the habit.\\n#Person1#: Well, we have classes and some medications that might help. I'll give you more information before you leave.\\n#Person2#: Ok, thanks doctor.\",\n",
       " 'summary': \"Mr. Smith's getting a check-up, and Doctor Hawkins advises him to have one every year. Hawkins'll give some information about their classes and medications to help Mr. Smith quit smoking.\",\n",
       " 'topic': 'get a check-up'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81e5be9c-a4c7-4c83-a2f4-620a869084bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'dev_0',\n",
       " 'dialogue': \"#Person1#: Hello, how are you doing today?\\n#Person2#: I ' Ve been having trouble breathing lately.\\n#Person1#: Have you had any type of cold lately?\\n#Person2#: No, I haven ' t had a cold. I just have a heavy feeling in my chest when I try to breathe.\\n#Person1#: Do you have any allergies that you know of?\\n#Person2#: No, I don ' t have any allergies that I know of.\\n#Person1#: Does this happen all the time or mostly when you are active?\\n#Person2#: It happens a lot when I work out.\\n#Person1#: I am going to send you to a pulmonary specialist who can run tests on you for asthma.\\n#Person2#: Thank you for your help, doctor.\",\n",
       " 'summary': '#Person2# has trouble breathing. The doctor asks #Person2# about it and will send #Person2# to a pulmonary specialist.',\n",
       " 'topic': 'see a doctor'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['validation'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8212419a-0b9d-49d6-8b1d-041f361c5353",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\.conda\\envs\\BIG-GenAI-env\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\hp\\.cache\\huggingface\\hub\\models--google--flan-t5-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    }
   ],
   "source": [
    "model_name = \"google/flan-t5-base\"\n",
    "original_model = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=torch.bfloat16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52d85dc0-24a0-4d9d-b23b-c1a859e47dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable model parameters: 247577856\n",
      "all model parameters: 247577856\n",
      "percentage of trainable model parameters: 100.00%\n"
     ]
    }
   ],
   "source": [
    "def print_number_of_trainable_model_parameters(model):\n",
    "    trainable_model_params = 0\n",
    "    all_model_params = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_model_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_model_params += param.numel()\n",
    "    return f\"trainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n",
    "\n",
    "print(print_number_of_trainable_model_parameters(original_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86368ff6-23e2-40db-be15-adad2627961c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test the Model with Zero Shot Inferencing\n",
    "index = 200\n",
    "\n",
    "dialogue = dataset['test'][index]['dialogue']\n",
    "summary = dataset['test'][index]['summary']   ### Reference\n",
    "\n",
    "\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Summarize the following conversation.\n",
    "\n",
    "{dialogue}\n",
    "\n",
    "Summary:\n",
    "\"\"\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors='pt')\n",
    "output = tokenizer.decode(\n",
    "    original_model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        max_new_tokens=200,\n",
    "    )[0],\n",
    "    skip_special_tokens=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22b0c9b3-81c6-4b5a-b447-4c36c15b4378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "\n",
      "Summarize the following conversation.\n",
      "\n",
      "#Person1#: Have you considered upgrading your system?\n",
      "#Person2#: Yes, but I'm not sure what exactly I would need.\n",
      "#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n",
      "#Person2#: That would be a definite bonus.\n",
      "#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n",
      "#Person2#: How can we do that?\n",
      "#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n",
      "#Person2#: No.\n",
      "#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n",
      "#Person2#: That sounds great. Thanks.\n",
      "\n",
      "Summary:\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "MODEL GENERATION - ZERO SHOT:\n",
      "#Person1#: I'm thinking of upgrading my computer.\n"
     ]
    }
   ],
   "source": [
    "dash_line = '-'.join('' for x in range(100))\n",
    "print(dash_line)\n",
    "print(f'INPUT PROMPT:\\n{prompt}')\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')\n",
    "print(dash_line)\n",
    "print(f'MODEL GENERATION - ZERO SHOT:\\n{output}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b68178f6-0554-475e-a1a9-2cca89bea812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"#Person1#: Have you considered upgrading your system?\\n#Person2#: Yes, but I'm not sure what exactly I would need.\\n#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\\n#Person2#: That would be a definite bonus.\\n#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\\n#Person2#: How can we do that?\\n#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\\n#Person2#: No.\\n#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\\n#Person2#: That sounds great. Thanks.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test'][200]['dialogue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e21d17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting peft\n",
      "  Downloading peft-0.15.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from peft) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from peft) (24.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from peft) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from peft) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from peft) (2.6.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from peft) (4.52.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from peft) (4.67.1)\n",
      "Collecting accelerate>=0.21.0 (from peft)\n",
      "  Using cached accelerate-1.7.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: safetensors in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from peft) (0.5.3)\n",
      "Requirement already satisfied: huggingface_hub>=0.25.0 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from peft) (0.32.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from huggingface_hub>=0.25.0->peft) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from huggingface_hub>=0.25.0->peft) (2025.3.0)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from huggingface_hub>=0.25.0->peft) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from huggingface_hub>=0.25.0->peft) (4.13.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from torch>=1.13.0->peft) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from torch>=1.13.0->peft) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from torch>=1.13.0->peft) (78.1.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from torch>=1.13.0->peft) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from tqdm->peft) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from requests->huggingface_hub>=0.25.0->peft) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from requests->huggingface_hub>=0.25.0->peft) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from requests->huggingface_hub>=0.25.0->peft) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from requests->huggingface_hub>=0.25.0->peft) (2025.4.26)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from transformers->peft) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from transformers->peft) (0.21.1)\n",
      "Downloading peft-0.15.2-py3-none-any.whl (411 kB)\n",
      "Using cached accelerate-1.7.0-py3-none-any.whl (362 kB)\n",
      "Installing collected packages: accelerate, peft\n",
      "\n",
      "   ---------------------------------------- 0/2 [accelerate]\n",
      "   ---------------------------------------- 0/2 [accelerate]\n",
      "   ---------------------------------------- 0/2 [accelerate]\n",
      "   ---------------------------------------- 0/2 [accelerate]\n",
      "   ---------------------------------------- 0/2 [accelerate]\n",
      "   ---------------------------------------- 0/2 [accelerate]\n",
      "   ---------------------------------------- 0/2 [accelerate]\n",
      "   ---------------------------------------- 0/2 [accelerate]\n",
      "   ---------------------------------------- 0/2 [accelerate]\n",
      "   ---------------------------------------- 0/2 [accelerate]\n",
      "   ---------------------------------------- 0/2 [accelerate]\n",
      "   ---------------------------------------- 0/2 [accelerate]\n",
      "   ---------------------------------------- 0/2 [accelerate]\n",
      "   ---------------------------------------- 0/2 [accelerate]\n",
      "   ---------------------------------------- 0/2 [accelerate]\n",
      "   ---------------------------------------- 0/2 [accelerate]\n",
      "   ---------------------------------------- 0/2 [accelerate]\n",
      "   ---------------------------------------- 0/2 [accelerate]\n",
      "   ---------------------------------------- 0/2 [accelerate]\n",
      "   ---------------------------------------- 0/2 [accelerate]\n",
      "   ---------------------------------------- 0/2 [accelerate]\n",
      "   ---------------------------------------- 0/2 [accelerate]\n",
      "   -------------------- ------------------- 1/2 [peft]\n",
      "   -------------------- ------------------- 1/2 [peft]\n",
      "   -------------------- ------------------- 1/2 [peft]\n",
      "   -------------------- ------------------- 1/2 [peft]\n",
      "   -------------------- ------------------- 1/2 [peft]\n",
      "   -------------------- ------------------- 1/2 [peft]\n",
      "   -------------------- ------------------- 1/2 [peft]\n",
      "   -------------------- ------------------- 1/2 [peft]\n",
      "   -------------------- ------------------- 1/2 [peft]\n",
      "   -------------------- ------------------- 1/2 [peft]\n",
      "   -------------------- ------------------- 1/2 [peft]\n",
      "   -------------------- ------------------- 1/2 [peft]\n",
      "   -------------------- ------------------- 1/2 [peft]\n",
      "   -------------------- ------------------- 1/2 [peft]\n",
      "   -------------------- ------------------- 1/2 [peft]\n",
      "   -------------------- ------------------- 1/2 [peft]\n",
      "   -------------------- ------------------- 1/2 [peft]\n",
      "   -------------------- ------------------- 1/2 [peft]\n",
      "   -------------------- ------------------- 1/2 [peft]\n",
      "   -------------------- ------------------- 1/2 [peft]\n",
      "   -------------------- ------------------- 1/2 [peft]\n",
      "   -------------------- ------------------- 1/2 [peft]\n",
      "   -------------------- ------------------- 1/2 [peft]\n",
      "   -------------------- ------------------- 1/2 [peft]\n",
      "   ---------------------------------------- 2/2 [peft]\n",
      "\n",
      "Successfully installed accelerate-1.7.0 peft-0.15.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~orch (c:\\Users\\hp\\.conda\\envs\\BIG-GenAI-env\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orch (c:\\Users\\hp\\.conda\\envs\\BIG-GenAI-env\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orch (c:\\Users\\hp\\.conda\\envs\\BIG-GenAI-env\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "! pip install peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38e7fd83-8789-4e1f-8d8a-44016b880fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameter Efficient Fine-Tuning (PEFT)\n",
    "#Setup the PEFT/LoRA model for Fine-Tuning\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=32, # Rank\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q\", \"v\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM # FLAN-T5\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37225319-097d-4946-9c7a-ec2a1e5a1265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable model parameters: 3538944\n",
      "all model parameters: 251116800\n",
      "percentage of trainable model parameters: 1.41%\n"
     ]
    }
   ],
   "source": [
    "#Add LoRA adapter layers/parameters to the original LLM to be trained.\n",
    "peft_model = get_peft_model(original_model,\n",
    "                            lora_config)\n",
    "print(print_number_of_trainable_model_parameters(peft_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79d6e3aa-c6de-4e75-a020-7cfd5b8bba33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 12460/12460 [00:14<00:00, 870.48 examples/s] \n",
      "Map: 100%|██████████| 500/500 [00:00<00:00, 1208.92 examples/s]\n",
      "Map: 100%|██████████| 1500/1500 [00:01<00:00, 1294.75 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(example):\n",
    "    start_prompt = 'Summarize the following conversation.\\n\\n'\n",
    "    end_prompt = '\\n\\nSummary: '\n",
    "    prompt = [start_prompt + dialogue + end_prompt for dialogue in example[\"dialogue\"]]\n",
    "    example['input_ids'] = tokenizer(prompt, padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
    "    example['labels'] = tokenizer(example[\"summary\"], padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
    "\n",
    "    return example\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_datasets = tokenized_datasets.remove_columns(['id', 'topic', 'dialogue', 'summary',])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8def9ec-2b89-4a1b-836c-04daa1a5ebc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 12460/12460 [00:10<00:00, 1197.28 examples/s]\n",
      "Filter: 100%|██████████| 500/500 [00:00<00:00, 1033.49 examples/s]\n",
      "Filter: 100%|██████████| 1500/1500 [00:01<00:00, 897.50 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = tokenized_datasets.filter(lambda example, index: index % 100 == 0, with_indices=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98ef93b3-dd69-43b7-a37d-a3a590e1ab08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of the datasets:\n",
      "Training: (125, 2)\n",
      "Validation: (5, 2)\n",
      "Test: (15, 2)\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'labels'],\n",
      "        num_rows: 125\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['input_ids', 'labels'],\n",
      "        num_rows: 5\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input_ids', 'labels'],\n",
      "        num_rows: 15\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shapes of the datasets:\")\n",
    "print(f\"Training: {tokenized_datasets['train'].shape}\")\n",
    "print(f\"Validation: {tokenized_datasets['validation'].shape}\")\n",
    "print(f\"Test: {tokenized_datasets['test'].shape}\")\n",
    "\n",
    "print(tokenized_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5af9f2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (1.7.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from accelerate) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from accelerate) (24.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from accelerate) (2.6.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from accelerate) (0.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2025.3.0)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.13.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from torch>=2.0.0->accelerate) (78.1.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.21.0->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\.conda\\envs\\big-genai-env\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2025.4.26)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~orch (c:\\Users\\hp\\.conda\\envs\\BIG-GenAI-env\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orch (c:\\Users\\hp\\.conda\\envs\\BIG-GenAI-env\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orch (c:\\Users\\hp\\.conda\\envs\\BIG-GenAI-env\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8d3b3b7c-190d-4e58-806d-73fdf5b02bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'dialogue', 'summary', 'topic', 'input_ids', 'labels'],\n",
      "    num_rows: 1246\n",
      "})\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Using the `Trainer` with `PyTorch` requires `accelerate>=0.26.0`: Please run `pip install transformers[torch]` or `pip install 'accelerate>=0.26.0'`",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(tokenized_subset)\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Define training arguments and create Trainer instance.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m peft_training_args = \u001b[43mTrainingArguments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauto_find_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Higher learning rate than full fine-tuning.\u001b[39;49;00m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_train_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogging_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\n\u001b[32m     26\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m peft_trainer = Trainer(\n\u001b[32m     29\u001b[39m     model=peft_model,\n\u001b[32m     30\u001b[39m     args=peft_training_args,\n\u001b[32m     31\u001b[39m     train_dataset=tokenized_subset,\n\u001b[32m     32\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:131\u001b[39m, in \u001b[36m__init__\u001b[39m\u001b[34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, eval_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, torch_empty_cache_steps, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, lr_scheduler_kwargs, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_safetensors, save_on_each_node, save_only_model, restore_callback_states_from_checkpoint, no_cuda, use_cpu, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, ddp_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, dataloader_prefetch_factor, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, fsdp, fsdp_min_num_params, fsdp_config, fsdp_transformer_layer_cls_to_wrap, accelerator_config, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, report_to, ddp_find_unused_parameters, ddp_bucket_cap_mb, ddp_broadcast_buffers, dataloader_pin_memory, dataloader_persistent_workers, skip_memory_metrics, use_legacy_prediction_loop, push_to_hub, resume_from_checkpoint, hub_model_id, hub_strategy, hub_token, hub_private_repo, hub_always_push, gradient_checkpointing, gradient_checkpointing_kwargs, include_inputs_for_metrics, include_for_metrics, eval_do_concat_batches, fp16_backend, push_to_hub_model_id, push_to_hub_organization, push_to_hub_token, mp_parameters, auto_find_batch_size, full_determinism, torchdynamo, ray_scope, ddp_timeout, torch_compile, torch_compile_backend, torch_compile_mode, include_tokens_per_second, include_num_input_tokens_seen, neftune_noise_alpha, optim_target_modules, batch_eval_metrics, eval_on_start, use_liger_kernel, eval_use_gather_object, average_tokens_across_devices)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hp\\.conda\\envs\\BIG-GenAI-env\\Lib\\site-packages\\transformers\\training_args.py:1738\u001b[39m, in \u001b[36mTrainingArguments.__post_init__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1736\u001b[39m \u001b[38;5;66;03m# Initialize device before we proceed\u001b[39;00m\n\u001b[32m   1737\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.framework == \u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_torch_available():\n\u001b[32m-> \u001b[39m\u001b[32m1738\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[32m   1740\u001b[39m \u001b[38;5;66;03m# Disable average tokens when using single device\u001b[39;00m\n\u001b[32m   1741\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.average_tokens_across_devices:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hp\\.conda\\envs\\BIG-GenAI-env\\Lib\\site-packages\\transformers\\training_args.py:2268\u001b[39m, in \u001b[36mTrainingArguments.device\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2264\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2265\u001b[39m \u001b[33;03mThe device used by this process.\u001b[39;00m\n\u001b[32m   2266\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2267\u001b[39m requires_backends(\u001b[38;5;28mself\u001b[39m, [\u001b[33m\"\u001b[39m\u001b[33mtorch\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m-> \u001b[39m\u001b[32m2268\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_setup_devices\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hp\\.conda\\envs\\BIG-GenAI-env\\Lib\\site-packages\\transformers\\utils\\generic.py:67\u001b[39m, in \u001b[36mcached_property.__get__\u001b[39m\u001b[34m(self, obj, objtype)\u001b[39m\n\u001b[32m     65\u001b[39m cached = \u001b[38;5;28mgetattr\u001b[39m(obj, attr, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cached \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     cached = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28msetattr\u001b[39m(obj, attr, cached)\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cached\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hp\\.conda\\envs\\BIG-GenAI-env\\Lib\\site-packages\\transformers\\training_args.py:2138\u001b[39m, in \u001b[36mTrainingArguments._setup_devices\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2136\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_sagemaker_mp_enabled():\n\u001b[32m   2137\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_accelerate_available():\n\u001b[32m-> \u001b[39m\u001b[32m2138\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m   2139\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUsing the `Trainer` with `PyTorch` requires `accelerate>=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mACCELERATE_MIN_VERSION\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m`: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2140\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPlease run `pip install transformers[torch]` or `pip install \u001b[39m\u001b[33m'\u001b[39m\u001b[33maccelerate>=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mACCELERATE_MIN_VERSION\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2141\u001b[39m         )\n\u001b[32m   2142\u001b[39m \u001b[38;5;66;03m# We delay the init of `PartialState` to the end for clarity\u001b[39;00m\n\u001b[32m   2143\u001b[39m accelerator_state_kwargs = {\u001b[33m\"\u001b[39m\u001b[33menabled\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33muse_configured_state\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m}\n",
      "\u001b[31mImportError\u001b[39m: Using the `Trainer` with `PyTorch` requires `accelerate>=0.26.0`: Please run `pip install transformers[torch]` or `pip install 'accelerate>=0.26.0'`"
     ]
    }
   ],
   "source": [
    "output_dir = f'./peft-dialogue-summary-training-{str(int(time.time()))}'\n",
    "\n",
    "# Define the fraction of the dataset you want to use (e.g., 10%)\n",
    "subset_fraction = 0.1\n",
    "\n",
    "# Calculate the number of samples to use\n",
    "subset_size = int(len(dataset[\"train\"]) * subset_fraction)\n",
    "\n",
    "# Create a subset of the dataset\n",
    "subset_dataset = dataset[\"train\"].shuffle(seed=42).select(range(subset_size))\n",
    "\n",
    "# Tokenize the subset\n",
    "tokenized_subset = subset_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "\n",
    "print(tokenized_subset)\n",
    "# Define training arguments and create Trainer instance.\n",
    "\n",
    "peft_training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    auto_find_batch_size=4,\n",
    "    learning_rate=1e-3, # Higher learning rate than full fine-tuning.\n",
    "    num_train_epochs=10,\n",
    "    logging_steps=1,\n",
    "    max_steps=10\n",
    ")\n",
    "\n",
    "peft_trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=peft_training_args,\n",
    "    train_dataset=tokenized_subset,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbe2a0da-2019-4709-885b-afcaacc8eb5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'peft_trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mpeft_trainer\u001b[49m.train()\n\u001b[32m      3\u001b[39m peft_model_path=\u001b[33m\"\u001b[39m\u001b[33m./peft-dialogue-summary-checkpoint-local\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      5\u001b[39m peft_trainer.model.save_pretrained(peft_model_path)\n",
      "\u001b[31mNameError\u001b[39m: name 'peft_trainer' is not defined"
     ]
    }
   ],
   "source": [
    "peft_trainer.train()\n",
    "\n",
    "peft_model_path=\"./peft-dialogue-summary-checkpoint-local\"\n",
    "\n",
    "peft_trainer.model.save_pretrained(peft_model_path)\n",
    "tokenizer.save_pretrained(peft_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93defd1-438b-491b-a130-edd5b88cf2cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99ddef7-da60-4fd3-9313-261db8a47064",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20945f0d-be3e-49db-aacd-1a6e34500253",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dde56c-aeb5-4291-9bfe-b946ef7ad2c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450925cd-2aba-452f-88b7-6b47937caedc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5650cc97-2438-4741-a7a9-2f0878956bad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f3b7e6-b1cb-4c34-a31c-75840b3ca19e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b2ee3d-f1f9-4539-ad83-95c76137e296",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760e3ffb-3c7e-4d66-94b4-5d0a9100b57c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BIG-GenAI-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
